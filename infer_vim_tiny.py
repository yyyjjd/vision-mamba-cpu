import torch
from torchvision import transforms
from fvcore.nn import FlopCountAnalysis
import time
import sys
import os

# è®¾ç½®CPUç¯å¢ƒå˜é‡ï¼Œå¼ºåˆ¶ä½¿ç”¨fallbackå®ç°
os.environ["CAUSAL_CONV1D_FORCE_FALLBACK"] = "TRUE"
os.environ["SELECTIVE_SCAN_FORCE_FALLBACK"] = "TRUE"

# 1. å¯¼å…¥æ¨¡å‹æ³¨å†Œå‡½æ•°
sys.path.append(os.path.dirname(__file__))  # ä¿è¯èƒ½importæœ¬åœ°æ¨¡å—

# æ·»åŠ mamba-1p1p1è·¯å¾„ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°mamba_ssmåŒ…
mamba_path = os.path.join(os.path.dirname(__file__), 'mamba-1p1p1')
if os.path.exists(mamba_path):
    sys.path.insert(0, mamba_path)
    print(f"[INFO] Added mamba path: {mamba_path}")

from models_mamba import (
    vim_tiny_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2,
    vim_small_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2
)

# é…ç½®
MODEL_TYPE = 'vim_small'  # å¯é€‰: 'vim_tiny', 'vim_small'

# æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®é…ç½®
if MODEL_TYPE == 'vim_tiny':
    CKPT_PATH = 'vim_t_midclstok_76p1acc.pth'  # vim_tinyæƒé‡è·¯å¾„
    MODEL_FUNC = vim_tiny_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2
    EMBED_DIM = 192
    DEPTH = 24
    D_STATE = 16
elif MODEL_TYPE == 'vim_small':
    CKPT_PATH = 'vim_s_midclstok_80p5acc.pth'  # vim_smallæƒé‡è·¯å¾„ - è¯·æ ¹æ®å®é™…æ–‡ä»¶åè°ƒæ•´
    MODEL_FUNC = vim_small_patch16_224_bimambav2_final_pool_mean_abs_pos_embed_with_midclstok_div2
    EMBED_DIM = 384
    DEPTH = 24
    D_STATE = 16
else:
    raise ValueError(f"Unsupported model type: {MODEL_TYPE}")

DEVICE = 'cpu'  # æ ‘è“æ´¾å»ºè®®ç”¨cpu
BATCH_SIZE = 8
NUM_IMAGES = 100  # å¯æ”¹ä¸º1000
input_size = 224

print(f"[INFO] Using model: {MODEL_TYPE}")
print(f"[INFO] Embed dim: {EMBED_DIM}, Depth: {DEPTH}, D_state: {D_STATE}")

# 2. åŠ è½½æ¨¡å‹
model = MODEL_FUNC(num_classes=1000)
model.eval()
model.to(DEVICE)

# æ£€æŸ¥æƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(CKPT_PATH):
    print(f"[WARNING] Checkpoint file {CKPT_PATH} not found!")
    print(f"[INFO] Please make sure the checkpoint file exists or update CKPT_PATH")
    print(f"[INFO] For vim_small, you might need to download the weights first")
    print(f"[INFO] You can set MODEL_TYPE = 'vim_tiny' to use the existing tiny model")
else:
    ckpt = torch.load(CKPT_PATH, map_location=DEVICE, weights_only=False)
    if 'model' in ckpt:
        ckpt = ckpt['model']
    state_dict = model.state_dict()
    model.load_state_dict(ckpt, strict=True)
    print(f"[INFO] Successfully loaded checkpoint: {CKPT_PATH}")

# 3. ç”Ÿæˆéšæœºå›¾ç‰‡æ•°æ®
all_imgs = torch.randn(NUM_IMAGES, 3, input_size, input_size)

# 4. FLOPs ç»Ÿè®¡ï¼ˆåªéœ€ä¸€æ¬¡ï¼Œå–ä¸€å¼ å›¾å³å¯ï¼‰
# flop_inputs = all_imgs[0:1].to(DEVICE)
# flops = FlopCountAnalysis(model, flop_inputs)
# print(f"Single image FLOPs: {flops.total() / 1e9:.2f} GFLOPs")

# æ›´ç²¾å‡†çš„ç†è®º FLOPs ä¼°ç®—ï¼ˆvim-tinyï¼Œ224x224è¾“å…¥ï¼‰
# img_size = 224
# patch_size = 16
# embed_dim = 192
# depth = 24
# d_state = 16
# num_classes = 1000
#
# num_patches = (img_size // patch_size) ** 2
#
# # Patch Embedding
# patch_embed_flops = 2 * embed_dim * num_patches * 3 * patch_size * patch_size
#
# # SelectiveScan/SSM
# ssm_flops_per_layer = 2 * embed_dim * num_patches * d_state
# ssm_total_flops = ssm_flops_per_layer * depth
#
# # MLP
# mlp_hidden_dim = 4 * embed_dim
# mlp_flops_per_layer = (
#     2 * num_patches * (embed_dim * mlp_hidden_dim) +  # ç¬¬ä¸€å±‚å…¨è¿æ¥
#     num_patches * mlp_hidden_dim +                   # æ¿€æ´»
#     2 * num_patches * (mlp_hidden_dim * embed_dim)   # ç¬¬äºŒå±‚å…¨è¿æ¥
# )
# mlp_total_flops = mlp_flops_per_layer * depth
#
# # LayerNorm
# layernorm_flops_per_layer = 4 * num_patches * embed_dim
# layernorm_total_flops = layernorm_flops_per_layer * depth * 2  # é€šå¸¸æ¯å±‚2æ¬¡LayerNorm
#
# # Residual Add
# residual_flops_per_layer = num_patches * embed_dim
# residual_total_flops = residual_flops_per_layer * depth * 2  # é€šå¸¸æ¯å±‚2æ¬¡æ®‹å·®
#
# # Head
# head_flops = 2 * embed_dim * num_classes
#
# # æ€» FLOPs
# total_flops = (
#     patch_embed_flops +
#     ssm_total_flops +
#     mlp_total_flops +
#     layernorm_total_flops +
#     residual_total_flops +
#     head_flops
# )
#
# print(f"[Precise Theoretical Estimate]")
# print(f"Patch Embedding FLOPs: {patch_embed_flops/1e6:.2f} MFLOPs")
# print(f"SelectiveScan FLOPs (total): {ssm_total_flops/1e6:.2f} MFLOPs")
# print(f"MLP FLOPs (total): {mlp_total_flops/1e6:.2f} MFLOPs")
# print(f"LayerNorm FLOPs (total): {layernorm_total_flops/1e6:.2f} MFLOPs")
# print(f"Residual Add FLOPs (total): {residual_total_flops/1e6:.2f} MFLOPs")
# print(f"Head FLOPs: {head_flops/1e6:.2f} MFLOPs")
# print(f"Total FLOPs (theoretical, single 224x224 image): {total_flops/1e9:.2f} GFLOPs\n")

# å‡†å¤‡è¾“å…¥æ•°æ®
inputs = torch.randn(1, 3, input_size, input_size)

# ç»Ÿè®¡å‚æ•°é‡ã€æ–‡ä»¶å¤§å°å’Œæ¨ç†æ—¶é—´
import time
import os
import numpy as np

def get_FileSize(filePath):
    filePath = str(filePath)
    fsize = os.path.getsize(filePath)
    fsize = fsize / float(1024 * 1024)
    return round(fsize, 2)

# è®¡ç®—æ¨¡å‹æ–‡ä»¶å¤§å°
mb = get_FileSize(CKPT_PATH)

# ç»Ÿè®¡å‚æ•°é‡
model_param_count = sum(p.numel() for p in model.parameters())

# ç»Ÿè®¡æ¨ç†æ—¶é—´
start = time.time()
outputs = model(inputs)
infer_time_record = time.time() - start

print(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {model_param_count/1e6:.2f}M")
print(f"ğŸ“Š æ¨¡å‹æ–‡ä»¶å¤§å°: {mb}MB")
print(f"ğŸ“Š å•å¼ å›¾ç‰‡æ¨ç†æ—¶é—´: {np.mean(infer_time_record):.4f}ç§’")

# 1. é¡¹ç›®æ ‡å‡†FLOPsè®¡ç®—æ–¹æ³•ï¼ˆdetectron2é£æ ¼ï¼‰
print("\n=== é¡¹ç›®æ ‡å‡†FLOPsè®¡ç®—æ–¹æ³•ï¼ˆdetectron2é£æ ¼ï¼‰===")
print("ğŸ”§ è¿™æ˜¯é¡¹ç›®det/tools/analyze_model.pyä¸­ä½¿ç”¨çš„æ ‡å‡†FLOPsè®¡ç®—æ–¹æ³•")
print("ğŸ”§ ç‰¹ç‚¹ï¼šåŸºäºfvcoreçš„è‡ªåŠ¨ç»Ÿè®¡ï¼Œæ ‡å‡†åŒ–ç¨‹åº¦é«˜")
try:
    # æ·»åŠ detè·¯å¾„ä»¥å¯¼å…¥é¡¹ç›®æ ‡å‡†åˆ†æå·¥å…·
    det_path = os.path.join(os.path.dirname(__file__), 'det')
    if os.path.exists(det_path):
        sys.path.insert(0, det_path)
        print(f"[INFO] Added det path: {det_path}")
        
        from detectron2.utils.analysis import FlopCountAnalysis as DetFlopCountAnalysis
        from detectron2.utils.analysis import flop_count_operators
        
        # æ–¹æ³•1ï¼šä½¿ç”¨detectron2çš„FlopCountAnalysis
        print("ğŸ” æ–¹æ³•1ï¼šdetectron2 FlopCountAnalysis")
        det_flops = DetFlopCountAnalysis(model, inputs)
        det_total_flops = det_flops.total()
        det_by_operator = det_flops.by_operator()
        
        print(f"detectron2 FLOPs: {det_total_flops/1e9:.3f}G")
        print("æŒ‰æ“ä½œç±»å‹ç»Ÿè®¡:")
        for op, count in det_by_operator.items():
            print(f"  {op}: {count/1e9:.3f}G")
        
        # æ–¹æ³•2ï¼šä½¿ç”¨flop_count_operatorså‡½æ•°
        print("\nğŸ” æ–¹æ³•2ï¼šflop_count_operators")
        # å‡†å¤‡detectron2æ ¼å¼çš„è¾“å…¥
        det_inputs = [{"image": inputs}]
        op_flops = flop_count_operators(model, det_inputs)
        
        print("æ“ä½œçº§åˆ«FLOPsç»Ÿè®¡:")
        for op, count in op_flops.items():
            print(f"  {op}: {count:.3f}G")
        
        sum_op_flops = sum(op_flops.values())
        print(f"æ€»FLOPs (flop_count_operators): {sum_op_flops:.3f}G")
        
    else:
        print("âŒ detç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡é¡¹ç›®æ ‡å‡†FLOPsè®¡ç®—")
        print("   è¯·ç¡®ä¿detç›®å½•åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹")
        
except ImportError as e:
    print(f"âŒ å¯¼å…¥detectron2åˆ†æå·¥å…·å¤±è´¥: {e}")
    print("   å¯èƒ½åŸå› : detectron2æœªå®‰è£…æˆ–è·¯å¾„é…ç½®é—®é¢˜")
except Exception as e:
    print(f"âŒ é¡¹ç›®æ ‡å‡†FLOPsè®¡ç®—å¤±è´¥: {e}")



# 2. è‡ªå®šä¹‰ç†è®ºFLOPsè®¡ç®—ï¼ˆé’ˆå¯¹BiMamba v2ä¼˜åŒ–ï¼‰
print("\n=== è‡ªå®šä¹‰ç†è®ºFLOPsè®¡ç®—ï¼ˆé’ˆå¯¹BiMamba v2ä¼˜åŒ–ï¼‰===")
print("ğŸ”§ ç‰¹ç‚¹ï¼šæ‰‹åŠ¨è®¡ç®—æ¯ä¸ªæ¨¡å—çš„FLOPsï¼ŒåŒ…å«BiMamba v2ç‰¹æœ‰çš„åŒå‘å¤„ç†æ“ä½œ")

# åŒé‡éªŒè¯ï¼šæ—¢ä»æ¨¡å‹è·å–ï¼Œåˆæä¾›ç¡¬ç¼–ç fallback

# è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ¨¡å‹çš„æ‰€æœ‰å±æ€§
print("ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ¨¡å‹å±æ€§")
model_attrs = [attr for attr in dir(model) if not attr.startswith('_')]
print(f"æ¨¡å‹å±æ€§æ•°é‡: {len(model_attrs)}")
print(f"å‰10ä¸ªå±æ€§: {model_attrs[:10]}")

# æŸ¥æ‰¾å¯èƒ½åŒ…å«å±‚çš„å±æ€§
layer_attrs = [attr for attr in model_attrs if 'layer' in attr.lower() or 'block' in attr.lower()]
print(f"å¯èƒ½çš„å±‚å±æ€§: {layer_attrs}")

try:
    # æ–¹æ³•1ï¼šä»æ¨¡å‹å®ä¾‹ä¸­è·å–å‚æ•°
    img_size = model.patch_embed.img_size[0]
    patch_size = model.patch_embed.patch_size[0]
    embed_dim = model.embed_dim
    num_classes = model.head.out_features
    num_patches = model.patch_embed.num_patches
    
    # å°è¯•è·å–depth - ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•
    depth = None
    if hasattr(model, 'blocks'):
        depth = len(model.blocks)
    elif hasattr(model, 'layers'):
        depth = len(model.layers)
    elif hasattr(model, 'depth'):
        depth = model.depth
    elif hasattr(model, 'num_layers'):
        depth = model.num_layers
    else:
        # å°è¯•ä»æ¨¡å‹çš„å…¶ä»–å±æ€§æ¨æ–­
        for attr_name in dir(model):
            if 'layer' in attr_name.lower() or 'block' in attr_name.lower():
                attr = getattr(model, attr_name)
                if hasattr(attr, '__len__'):
                    depth = len(attr)
                    break
    
    if depth is None:
        depth = 24  # fallback
    
    # å°è¯•è·å–d_state - ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•
    d_state = 16  # é»˜è®¤å€¼
    try:
        if hasattr(model, 'blocks') and len(model.blocks) > 0:
            if hasattr(model.blocks[0], 'mixer') and hasattr(model.blocks[0].mixer, 'd_state'):
                d_state = model.blocks[0].mixer.d_state
    except:
        pass
    
    print("âœ… æˆåŠŸä»æ¨¡å‹è·å–å‚æ•°")
    
except Exception as e:
    print(f"âš ï¸ ä»æ¨¡å‹è·å–å‚æ•°å¤±è´¥: {e}")
    print(f"ğŸ”„ ä½¿ç”¨ç¡¬ç¼–ç å‚æ•°ï¼ˆ{MODEL_TYPE} æ ‡å‡†é…ç½®ï¼‰")
    
    # æ–¹æ³•2ï¼šç¡¬ç¼–ç å‚æ•°ï¼ˆæ ¹æ®æ¨¡å‹ç±»å‹ï¼‰
    img_size = 224
    patch_size = 16
    embed_dim = EMBED_DIM  # ä½¿ç”¨å…¨å±€å˜é‡
    depth = DEPTH  # ä½¿ç”¨å…¨å±€å˜é‡
    d_state = D_STATE  # ä½¿ç”¨å…¨å±€å˜é‡
    num_classes = 1000
    num_patches = (img_size // patch_size) ** 2

# éªŒè¯å‚æ•°åˆç†æ€§
print(f"ğŸ“Š æ¨¡å‹å‚æ•°éªŒè¯:")
print(f"   img_size: {img_size}")
print(f"   patch_size: {patch_size}")
print(f"   embed_dim: {embed_dim}")
print(f"   depth: {depth}")
print(f"   d_state: {d_state}")
print(f"   num_classes: {num_classes}")
print(f"   num_patches: {num_patches}")

# å‚æ•°åˆç†æ€§æ£€æŸ¥
assert img_size == 224, f"img_size åº”è¯¥æ˜¯ 224ï¼Œå®é™…æ˜¯ {img_size}"
assert patch_size == 16, f"patch_size åº”è¯¥æ˜¯ 16ï¼Œå®é™…æ˜¯ {patch_size}"
assert embed_dim == EMBED_DIM, f"embed_dim åº”è¯¥æ˜¯ {EMBED_DIM}ï¼Œå®é™…æ˜¯ {embed_dim}"
assert depth == DEPTH, f"depth åº”è¯¥æ˜¯ {DEPTH}ï¼Œå®é™…æ˜¯ {depth}"
assert d_state == D_STATE, f"d_state åº”è¯¥æ˜¯ {D_STATE}ï¼Œå®é™…æ˜¯ {d_state}"
assert num_patches == 196, f"num_patches åº”è¯¥æ˜¯ 196ï¼Œå®é™…æ˜¯ {num_patches}"

print("âœ… æ‰€æœ‰å‚æ•°éªŒè¯é€šè¿‡ï¼")

# 1. Patch Embedding FLOPs (thop èƒ½ç»Ÿè®¡åˆ°)
patch_embed_flops = 2 * embed_dim * num_patches * 3 * patch_size * patch_size
print(f"Patch Embedding FLOPs: {patch_embed_flops/1e6:.2f} MFLOPs")

# 2. Mamba å— FLOPs (thop ç»Ÿè®¡ä¸åˆ°)
# æ¯ä¸ª Mamba å—åŒ…å«ï¼š
# - å› æœå·ç§¯
# - Selective Scan (SSM) - æ³¨æ„ï¼šBiMamba v2 æœ‰å‰å‘å’Œåå‘ä¸¤ä¸ªå¤„ç†
# - MLP
# - LayerNorm

# å› æœå·ç§¯ FLOPs (BiMamba v2 æœ‰å‰å‘å’Œåå‘ä¸¤ä¸ªå·ç§¯)
conv1d_flops_per_layer = 2 * embed_dim * num_patches * 4  # width=4, åŒå‘å¤„ç†
conv1d_total_flops = conv1d_flops_per_layer * depth

# Selective Scan FLOPs (BiMamba v2 æœ‰å‰å‘å’Œåå‘ä¸¤ä¸ª SSM)
ssm_flops_per_layer = 2 * embed_dim * num_patches * d_state * 2  # åŒå‘å¤„ç†ï¼Œæ‰€ä»¥ä¹˜ä»¥2
ssm_total_flops = ssm_flops_per_layer * depth

# MLP FLOPs (BiMamba v2 çš„å®é™…ç»“æ„)
# ä»æºç åˆ†æï¼šBiMamba v2 æœ‰å‰å‘å’Œåå‘ä¸¤ä¸ªå¤„ç†è·¯å¾„
# æ¯ä¸ªè·¯å¾„åŒ…å«ï¼šx_proj, dt_proj, out_proj

# è¾“å…¥æŠ•å½± (x_proj å’Œ x_proj_b) - åŒå‘å¤„ç†
# x_proj: (batch, seqlen, embed_dim) -> (batch*seqlen, embed_dim*2)
x_proj_flops_per_layer = 2 * num_patches * embed_dim * (embed_dim * 2)  # åŒå‘å¤„ç†ï¼Œexpand=2
x_proj_total_flops = x_proj_flops_per_layer * depth

# æ—¶é—´æ­¥æŠ•å½± (dt_proj å’Œ dt_proj_b) - åŒå‘å¤„ç†
# dt_proj: (batch*seqlen, embed_dim*2) -> (batch*seqlen, dt_rank)
dt_rank = 16  # é»˜è®¤å€¼
dt_proj_flops_per_layer = 2 * num_patches * (embed_dim * 2) * dt_rank  # åŒå‘å¤„ç†
dt_proj_total_flops = dt_proj_flops_per_layer * depth

# è¾“å‡ºæŠ•å½± (out_proj) - åªåœ¨æœ€åç»Ÿä¸€å¤„ç†ï¼Œä¸æ˜¯æ¯å±‚éƒ½æœ‰
out_proj_flops_per_layer = 2 * num_patches * embed_dim * embed_dim  # åŒå‘å¤„ç†
out_proj_total_flops = out_proj_flops_per_layer * depth  # æ¯å±‚éƒ½æœ‰è¾“å‡ºæŠ•å½±

# æ€» MLP FLOPs (åŒ…å«æ¯å±‚çš„è¾“å…¥æŠ•å½±ã€æ—¶é—´æ­¥æŠ•å½±ï¼Œä»¥åŠæ¯å±‚çš„è¾“å‡ºæŠ•å½±)
mlp_total_flops = x_proj_total_flops + dt_proj_total_flops + out_proj_total_flops

# LayerNorm FLOPs
layernorm_flops_per_layer = 4 * num_patches * embed_dim
layernorm_total_flops = layernorm_flops_per_layer * depth * 2  # é€šå¸¸æ¯å±‚2æ¬¡LayerNorm

# æ®‹å·®è¿æ¥ FLOPs
residual_flops_per_layer = num_patches * embed_dim
residual_total_flops = residual_flops_per_layer * depth * 2

# BiMamba v2 ç‰¹æœ‰çš„é¢å¤–è®¡ç®—
# 1. åºåˆ—ç¿»è½¬æ“ä½œ
flip_flops_per_layer = num_patches * embed_dim  # ç¿»è½¬æ“ä½œ
flip_total_flops = flip_flops_per_layer * depth * 2  # å‰å‘å’Œåå‘å„ä¸€æ¬¡

# 2. è¾“å‡ºåˆå¹¶æ“ä½œ
merge_flops_per_layer = num_patches * embed_dim  # åŠ æ³•æ“ä½œ
merge_total_flops = merge_flops_per_layer * depth

# 3. é™¤æ³•æ“ä½œ (if_divide_out=True)
divide_flops_per_layer = num_patches * embed_dim  # é™¤æ³•æ“ä½œ
divide_total_flops = divide_flops_per_layer * depth

# 3. Head FLOPs (thop èƒ½ç»Ÿè®¡åˆ°)
head_flops = 2 * embed_dim * num_classes

# æ€»ç†è®º FLOPs
total_theoretical_flops = (
    patch_embed_flops +
    conv1d_total_flops +
    ssm_total_flops +
    mlp_total_flops +
    layernorm_total_flops +
    residual_total_flops +
    flip_total_flops +      # BiMamba v2 ç¿»è½¬æ“ä½œ
    merge_total_flops +     # BiMamba v2 åˆå¹¶æ“ä½œ
    divide_total_flops +    # BiMamba v2 é™¤æ³•æ“ä½œ
    head_flops
)

print(f"ğŸ“Š FLOPs åˆ†è§£ (ç†è®ºè®¡ç®—):")
print(f"  Patch Embedding: {patch_embed_flops/1e9:.3f}G")
print(f"  å› æœå·ç§¯ (BiMamba v2): {conv1d_total_flops/1e9:.3f}G")
print(f"  Selective Scan (BiMamba v2): {ssm_total_flops/1e9:.3f}G")
print(f"  è¾“å…¥æŠ•å½± (BiMamba v2): {x_proj_total_flops/1e9:.3f}G")
print(f"  æ—¶é—´æ­¥æŠ•å½± (BiMamba v2): {dt_proj_total_flops/1e9:.3f}G")
print(f"  è¾“å‡ºæŠ•å½± (BiMamba v2): {out_proj_total_flops/1e9:.3f}G")
print(f"  LayerNorm: {layernorm_total_flops/1e9:.3f}G")
print(f"  æ®‹å·®è¿æ¥: {residual_total_flops/1e9:.3f}G")
print(f"  åºåˆ—ç¿»è½¬ (BiMamba v2): {flip_total_flops/1e9:.3f}G")
print(f"  è¾“å‡ºåˆå¹¶ (BiMamba v2): {merge_total_flops/1e9:.3f}G")
print(f"  é™¤æ³•æ“ä½œ (BiMamba v2): {divide_total_flops/1e9:.3f}G")
print(f"  Head: {head_flops/1e9:.3f}G")
print(f"  æ€»è®¡: {total_theoretical_flops/1e9:.3f}G")



# 3. ç»¼åˆFLOPså¯¹æ¯”æ€»ç»“
print(f"\n=== ç»¼åˆFLOPså¯¹æ¯”æ€»ç»“ ===")
print(f"ğŸ“Š {MODEL_TYPE} æ¨¡å‹ FLOPs ç»Ÿè®¡å¯¹æ¯”:")

# å°è¯•è·å–é¡¹ç›®æ ‡å‡†FLOPsç»“æœè¿›è¡Œå¯¹æ¯”
try:
    if 'det_total_flops' in locals():
        print(f"  é¡¹ç›®æ ‡å‡† (detectron2): {det_total_flops/1e9:.3f}G")
    if 'sum_op_flops' in locals():
        print(f"  é¡¹ç›®æ ‡å‡† (operators): {sum_op_flops:.3f}G")
except:
    pass

print(f"  è‡ªå®šä¹‰ç†è®ºè®¡ç®—:      {total_theoretical_flops/1e9:.3f}G")

print(f"\nğŸ’¡ è¯´æ˜:")
print(f"  - é¡¹ç›®æ ‡å‡†ï¼šdetectron2æ¡†æ¶çš„æ ‡å‡†FLOPsè®¡ç®—æ–¹æ³•")
print(f"  - è‡ªå®šä¹‰ç†è®ºï¼šåŸºäºæ¨¡å‹æ¶æ„çš„æ‰‹åŠ¨è®¡ç®—ï¼ŒåŒ…å«BiMamba v2çš„ç‰¹æ®Šæ“ä½œ")

# 4. ååé‡ç»Ÿè®¡
# num_batches = (len(all_imgs) + BATCH_SIZE - 1) // BATCH_SIZE
# start = time.time()
# with torch.no_grad():
#     for i in range(num_batches):
#         batch = all_imgs[i*BATCH_SIZE:(i+1)*BATCH_SIZE].to(DEVICE)
#         _ = model(batch)
# end = time.time()
# total_time = end - start
# throughput = len(all_imgs) / total_time

# print(f"Processed {len(all_imgs)} images in {total_time:.2f} seconds")
# print(f"Average throughput: {throughput:.2f} images/second")
# print(f"Average time per image: {total_time / len(all_imgs):.4f} seconds")

# ååé‡ç»Ÿè®¡å‚æ•°
batch_size = 1
num_images = 1000
log_interval = 10
log_file = "throughput_log.txt"

throughputs = []
start_time = time.time()

with open(log_file, "w") as f:
    for i in range(num_images):
        input_tensor = torch.randn(batch_size, 3, 224, 224)
        t0 = time.time()
        with torch.no_grad():
            _ = model(input_tensor)
        t1 = time.time()
        throughput = batch_size / (t1 - t0)
        throughputs.append(throughput)
        
        if (i + 1) % log_interval == 0:
            avg_throughput = sum(throughputs[-log_interval:]) / log_interval
            f.write(f"Batch {i+1}: {avg_throughput:.2f} images/sec\n")
            print(f"Batch {i+1}: {avg_throughput:.2f} images/sec")

end_time = time.time()
total_time = end_time - start_time
avg_throughput = sum(throughputs) / len(throughputs)

print(f"\n=== ååé‡ç»Ÿè®¡ç»“æœ ===")
print(f"æ€»å¤„ç†æ—¶é—´: {total_time:.2f} ç§’")
print(f"å¹³å‡ååé‡: {avg_throughput:.2f} images/sec")
print(f"å¹³å‡æ¯å¼ å›¾ç‰‡æ—¶é—´: {total_time / num_images:.4f} ç§’")
print(f"è¯¦ç»†æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")

# 4. ç»Ÿè®¡å‚æ•°é‡
model_param_count = sum(p.numel() for p in model.parameters())
print(f"\nğŸ“Š æ¨¡å‹å‚æ•°é‡: {model_param_count/1e6:.2f}M")

# ä¿å­˜æ¨¡å‹æƒé‡åˆ°æœ¬åœ°
model_cpu = model.to('cpu')
save_path = f"{MODEL_TYPE}_cpu.pth"
torch.save(model_cpu.state_dict(), save_path)
print(f"æ¨¡å‹æƒé‡å·²ä¿å­˜åˆ° {save_path}") 